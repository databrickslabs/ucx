[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build]
sources = ["src"]
include = ["src"]

[project]
name = "databricks-labs-ucx"
dynamic = ["version"]
description = ''
readme = "README.md"
requires-python = ">=3.10.6" # latest available in DBR 13.2
keywords = []
authors = [
    { name = "Ivan Trusov", email = "ivan.trusov@databricks.com" },
    { name = "Serge Smertin", email = "serge.smertin@databricks.com" },
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
]
dependencies = [
    "databricks-sdk~=0.6.0",
    "typer[all]>=0.9.0,<0.10.0",
    "pyhocon>=0.3.60,<0.4.0",
    "pydantic>=2.0.3, <3.0.0",
    "PyYAML>=6.0.0,<7.0.0",
    "ratelimit>=2.2.1,<3.0.0",
    "pandas>=2.0.3,<3.0.0",
    "python-dotenv>=1.0.0,<=2.0.0",
    "tenacity>=8.2.2,<9.0.0",
]

[project.optional-dependencies]
dbconnect = [
    "databricks-connect>=13.2.0,<=14.0.0"
]
test = [
    "coverage[toml]>=6.5",
    "pytest",
    "pytest-cov>=4.0.0,<5.0.0",
    "pytest-mock>=3.0.0,<4.0.0",
]

[project.scripts]
ucx = "databricks.labs.ucx.__main__:entrypoint"

[project.urls]
Issues = "https://github.com/databricks/UC-Upgrade/issues"
Source = "https://github.com/databricks/UC-Upgrade"

[tool.hatch.version]
path = "src/databricks/labs/ucx/__about__.py"

[tool.hatch.envs.unit]
dependencies = [
    "databricks-labs-ucx[test]",
    "pyspark>=3.4.0,<=3.5.0",
    "delta-spark>=2.4.0,<3.0.0"
]

[tool.hatch.envs.unit.scripts]
test = "pytest --cov src tests/unit/test_secrets_api.py"
test-cov-report = "pytest --cov src tests/unit/test_secrets_api.py --cov-report=html"

[tool.hatch.envs.integration]
dependencies = [
    "databricks-labs-ucx[test]",
    "databricks-labs-ucx[dbconnect]",
    "delta-spark>=2.4.0,<3.0.0"
]

[tool.hatch.envs.integration.scripts]
test = "pytest --cov src tests/integration"

[tool.hatch.envs.lint]
detached = true
dependencies = [
    "black>=23.1.0",
    "ruff>=0.0.243",
    "isort>=2.5.0"
]
[tool.hatch.envs.lint.scripts]
fmt = [
    "isort .",
    "black .",
    "ruff  . --fix",
]
verify = [
    "black --check .",
    "isort . --check-only",
    "ruff .",
]

[tool.isort]
skip_glob = [
    "notebooks/*.py"
]
profile = "black"

[tool.pytest.ini_options]
addopts = "-s -p no:warnings -vv --cache-clear"
filterwarnings = [
    "ignore:::.*pyspark.broadcast*",
    "ignore:::.*pyspark.sql.pandas.utils*"
]

[tool.black]
target-version = ["py310"]
line-length = 120
skip-string-normalization = true

[tool.ruff]
target-version = "py310"
line-length = 120
select = [
    "A",
    "ARG",
    "B",
    "C",
    "E",
    "EM",
    "F",
    "FBT",
    "I",
    "ICN",
    "ISC",
    "N",
    "PLC",
    "PLE",
    "PLR",
    "PLW",
    "Q",
    "RUF",
    "S",
    "T",
    "TID",
    "UP",
    "W",
    "YTT",
]
ignore = [
    # Allow non-abstract empty methods in abstract base classes
    "B027",
    # Allow boolean positional values in function calls, like `dict.get(... True)`
    "FBT003",
    # Ignore checks for possible passwords and SQL statement construction
    "S105", "S106", "S107", "S603", "S608",
    # Allow print statements
    "T201",
    # Allow asserts
    "S101",
    # Allow standard random generators
    "S311",
    # Ignore complexity
    "C901", "PLR0911", "PLR0912", "PLR0913", "PLR0915",
    # Ignore flaky Import block is un-sorted or un-formatted
    "I001"
]
extend-exclude = [
    "notebooks/*.py"
]

[tool.ruff.isort]
known-first-party = ["databricks.labs.ucx"]

[tool.ruff.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
"tests/**/*" = ["PLR2004", "S101", "TID252"]

[tool.coverage.run]
branch = true
parallel = true

[tool.coverage.report]
exclude_lines = [
    "no cov",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
]
