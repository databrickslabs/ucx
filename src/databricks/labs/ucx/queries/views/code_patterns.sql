SELECT
  col1 AS pattern,
  col2 AS issue
FROM VALUES
  ('hive_metastore.', 'AF300.6 - 3 level namespace'),
  ('spark.catalog.', 'AF301.1 - spark.catalog.x'),
  ('spark._jsparkSession.catalog', 'AF301.2 - spark.catalog.x'),
  ('spark._jspark', 'AF302.1 - Arbitrary Java'),
  ('spark._jvm', 'AF302.2 - Arbitrary Java'),
  ('._jdf', 'AF302.3 - Arbitrary Java'),
  ('._jcol', 'AF302.4 - Arbitrary Java'),
  ('._jvm', 'AF302.5 - Arbitrary Java'),
  ('._jvm.org.apache.log4j', 'AF302.6 - Arbitrary Java'),
  ('spark.udf.registerJavaFunction', 'AF303.1 - Java UDF'),
  ('spark.read.format("jdbc")', 'AF304.1 - JDBC datasource'),
  ('boto3', 'AF305.1 - boto3'),
  ('s3fs', 'AF305.2 - s3fs'),
  ('dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson()', 'AF306.1 - dbutils...getContext'),
  ('dbutils.notebook.entry_point.getDbutils().notebook().getContext()', 'AF306.2 - dbutils...getContext'),
  ('dbutils.credentials.', 'AF310.1 - credential passthrough'),
  ('dbutils.fs.', 'AF311.1 - dbutils.fs'),
  ('dbutils.fs.mount', 'AF311.2 - dbutils mount(s)'),
  ('dbutils.fs.refreshMounts', 'AF311.3 - dbutils mount(s)'),
  ('dbutils.fs.unmount', 'AF311.4 - dbutils mount(s)'),
  ('dbfs:/mnt', 'AF311.5 - mount points'),
  ('dbfs:/', 'AF311.6 - dbfs usage'),
  ('/dbfs/', 'AF311.7 - dbfs usage'),
  ('spark.sparkContext', 'AF313.1 - SparkContext'),
  ('from pyspark.sql import SQLContext', 'AF313.2 - SparkContext'),
  ('import org.apache.spark.sql.SQLContext', 'AF313.2 - SparkContext'),
  ('.binaryFiles', 'AF313.3 - SparkContext'),
  ('.binaryRecords', 'AF313.4 - SparkContext'),
  ('.emptyRDD', 'AF313.5 - SparkContext'),
  ('.getConf', 'AF313.6 - SparkContext'),
  ('.hadoopFile', 'AF313.7 - SparkContext'),
  ('.hadoopRDD', 'AF313.8 - SparkContext'),
  ('.init_batched_serializer', 'AF313.9 - SparkContext'),
  ('.newAPIHadoopFile', 'AF313.10 - SparkContext'),
  ('.newAPIHadoopRDD', 'AF313.11 - SparkContext'),
  ('.parallelize', 'AF313.12 - SparkContext'),
  ('.pickleFile', 'AF313.13 - SparkContext'),
  ('.range', 'AF313.14 - SparkContext'),
  ('.rdd', 'AF313.15 - SparkContext'),
  ('.runJob', 'AF313.16 - SparkContext'),
  ('.sequenceFile', 'AF313.17 - SparkContext'),
  ('.setJobGroup', 'AF313.18 - SparkContext'),
  ('.setLocalProperty', 'AF313.19 - SparkContext'),
  ('.setSystemProperty', 'AF313.20 - SparkContext'),
  ('.stop', 'AF313.21 - SparkContext'),
  ('.textFile', 'AF313.22 - SparkContext'),
  ('.uiWebUrl', 'AF313.23 - SparkContext'),
  ('.union', 'AF313.24 - SparkContext'),
  ('.wholeTextFiles', 'AF313.25 - SparkContext'),
  ('sparknlp', 'AF314.1 - Distributed ML'),
  ('xgboost.spark', 'AF314.2 - Distributed ML'),
  ('catboost_spark', 'AF314.3 - Distributed ML'),
  ('ai.catboost:catboost-spark', 'AF314.4 - Distributed ML'),
  ('hyperopt', 'AF314.5 - Distributed ML'),
  ('SparkTrials', 'AF314.6 - Distributed ML'),
  ('horovod.spark', 'AF314.7 - Distributed ML'),
  ('ray.util.spark', 'AF314.8 - Distributed ML'),
  ('databricks.automl', 'AF314.9 - Distributed ML'),
  ('from graphframes', 'AF308.1 - Graphframes'),
  ('pyspark.ml.', 'AF309.1 - Spark ML'),
  ('UserDefinedAggregateFunction', 'AF315.1 - UDAF scala issue'),
  ('applyInPandas', 'AF315.2 - applyInPandas'),
  ('mapInPandas', 'AF315.3 - mapInPandas'),
  ('.trigger(continuous', 'AF330.1 - Streaming'),
  ('kafka.sasl.client.callback.handler.class', 'AF330.2 - Streaming'),
  ('kafka.sasl.login.callback.handler.class', 'AF330.3 - Streaming'),
  ('kafka.sasl.login.class', 'AF330.4 - Streaming'),
  ('kafka.partition.assignment.strategy', 'AF330.5 - Streaming'),
  ('kafka.ssl.truststore.location', 'AF330.6 - Streaming'),
  ('kafka.ssl.keystore.location', 'AF330.7 - Streaming'),
  ('cleanSource', 'AF330.8 - Streaming'),
  ('sourceArchiveDir', 'AF330.9 - Streaming'),
  ('applyInPandasWithState', 'AF330.10 - Streaming'),
  ('.format("socket")', 'AF330.11 - Streaming'),
  ('StreamingQueryListener', 'AF330.12 - Streaming'),
  ('applyInPandasWithState', 'AF330.13 - Streaming')