SELECT col1 AS pattern, col2 AS issue FROM values
  ('hive_metastore.',                           'AF300.6 - 3 level namespace'),
  ('spark.catalog.',                            'AF301.1 - spark.catalog.x'),
  ('spark._jsparkSession.catalog',              'AF301.2 - spark.catalog.x'),
  ('spark._jspark',                             'AF302.1 - Arbitrary Java'),
  ('spark._jvm',                                'AF302.2 - Arbitrary Java'),
  ('._jdf',                                     'AF302.3 - Arbitrary Java'),
  ('._jcol',                                    'AF302.4 - Arbitrary Java'),
  ('._jvm',                                     'AF302.5 - Arbitrary Java'),
  ('._jvm.org.apache.log4j',                    'AF302.6 - Arbitrary Java'),
  ('spark.udf.registerJavaFunction',            'AF303.1 - Java UDF'),
  
  ('spark.read.format("jdbc")',                 'AF304.1 - JDBC datasource'),
  ('boto3',                                     'AF305.1 - boto3'),
  ('s3fs',                                      'AF305.2 - s3fs'),

  ('dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson()', 'AF306.1 - dbutils...getContext'),
  ('dbutils.notebook.entry_point.getDbutils().notebook().getContext()',          'AF306.2 - dbutils...getContext'),
  
  ('dbutils.credentials.',                      'AF310.1 - credential passthrough'),
  ('dbutils.fs.',                               'AF311.1 - dbutils.fs'),
  ('dbutils.fs.mount',                          'AF311.2 - dbutils mount(s)'),
  ('dbutils.fs.refreshMounts',                  'AF311.3 - dbutils mount(s)'),
  ('dbutils.fs.unmount',                        'AF311.4 - dbutils mount(s)'),
  ('dbfs:/mnt', 			                          'AF311.5 - mount points'),
  ('dbfs:/', 			                              'AF311.6 - dbfs usage'),
  ('/dbfs/', 			                              'AF311.7 - dbfs usage'),


  ('spark.sparkContext',                        'AF313.1 - SparkContext'),
  ('from pyspark.sql import SQLContext',        'AF313.2 - SparkContext'),
  ('import org.apache.spark.sql.SQLContext',    'AF313.2 - SparkContext'),
  ('.binaryFiles',                              'AF313.3 - SparkContext'),
  ('.binaryRecords',                            'AF313.4 - SparkContext'),
  ('.emptyRDD',                                 'AF313.5 - SparkContext'),
  ('.getConf',                                  'AF313.6 - SparkContext'),
  ('.hadoopFile',                               'AF313.7 - SparkContext'),
  ('.hadoopRDD',                                'AF313.8 - SparkContext'),
  ('.init_batched_serializer',                  'AF313.9 - SparkContext'),
  ('.newAPIHadoopFile',                         'AF313.10 - SparkContext'),
  ('.newAPIHadoopRDD',                          'AF313.11 - SparkContext'),
  ('.parallelize',                              'AF313.12 - SparkContext'),
  ('.pickleFile',                               'AF313.13 - SparkContext'),
  ('.range',                                    'AF313.14 - SparkContext'),
  ('.rdd',                                      'AF313.15 - SparkContext'),
  ('.runJob',                                   'AF313.16 - SparkContext'),
  ('.sequenceFile',                             'AF313.17 - SparkContext'),
  ('.setJobGroup',                              'AF313.18 - SparkContext'),
  ('.setLocalProperty',                         'AF313.19 - SparkContext'),
  ('.setSystemProperty',                        'AF313.20 - SparkContext'),
  ('.stop',                                     'AF313.21 - SparkContext'),
  ('.textFile',                                 'AF313.22 - SparkContext'),
  ('.uiWebUrl',                                 'AF313.23 - SparkContext'),
  ('.union',                                    'AF313.24 - SparkContext'),
  ('.wholeTextFiles',                           'AF313.25 - SparkContext'),

  ('sparknlp',     			                        'AF314.1 - Distributed ML'),
  ('xgboost.spark',                             'AF314.2 - Distributed ML'),
  ('catboost_spark',                            'AF314.3 - Distributed ML'),
  ('ai.catboost:catboost-spark',                'AF314.4 - Distributed ML'),
  ('hyperopt',                                  'AF314.5 - Distributed ML'),
  ('SparkTrials',                               'AF314.6 - Distributed ML'),
  ('horovod.spark',                             'AF314.7 - Distributed ML'),
  ('ray.util.spark',                            'AF314.8 - Distributed ML'),
  ('databricks.automl',                         'AF314.9 - Distributed ML'),
  ('from graphframes',                          'AF308.1 - Graphframes'),
  ('pyspark.ml.',                               'AF309.1 - Spark ML'),

  ('UserDefinedAggregateFunction',              'AF315.1 - UDAF scala issue'),
  ('applyInPandas',                             'AF315.2 - applyInPandas'),
  ('mapInPandas',                               'AF315.3 - mapInPandas'),
  

  ('.trigger(continuous',                       'AF330.1 - Streaming'),
  ('kafka.sasl.client.callback.handler.class',  'AF330.2 - Streaming'),
  ('kafka.sasl.login.callback.handler.class',   'AF330.3 - Streaming'),
  ('kafka.sasl.login.class',                    'AF330.4 - Streaming'),
  ('kafka.partition.assignment.strategy',       'AF330.5 - Streaming'),
  ('kafka.ssl.truststore.location',             'AF330.6 - Streaming'),
  ('kafka.ssl.keystore.location',               'AF330.7 - Streaming'),
  ('cleanSource',                               'AF330.8 - Streaming'),
  ('sourceArchiveDir',                          'AF330.9 - Streaming'),
  ('applyInPandasWithState',                    'AF330.10 - Streaming'),
  ('.format("socket")',                         'AF330.11 - Streaming'),
  ('StreamingQueryListener',                    'AF330.12 - Streaming'),
  ('applyInPandasWithState',                    'AF330.13 - Streaming')